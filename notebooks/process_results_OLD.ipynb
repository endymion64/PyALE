{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Load logged trial data. This assumes data is stored in folders \n",
    "data/SARSA_a_<alpha>_l_<lambda>_e_<epsilon>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "numtrials=10\n",
    "numep = 200\n",
    "alpha =0.5\n",
    "eps = 0.05\n",
    "lambdas = [0.,0.5,1.] #try multiple lambdas\n",
    "\n",
    "#store data in 5d array\n",
    "steps = np.zeros((len(lambdas),numep,numtrials))\n",
    "\n",
    "for t in range(1,numtrials+1):\n",
    "    for i,l in enumerate(lambdas):\n",
    "        with open('data/SARSA_a_'+str(alpha)+'_l_'+str(l)+'_e_'+str(eps)+'/SARSA_log.'+str(t),'rb') as f:\n",
    "            log = pickle.load(f)\n",
    "            steps[i,:,t-1] = np.array(log['steps'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Calculate basic statistics of number of steps over different trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "mean_steps = np.mean(steps,axis=2) #average steps\n",
    "err =stats.sem(steps,axis=2) #standard error of mean\n",
    "\n",
    "#statistics for first 50 episodes\n",
    "mean_50 = np.mean(steps[:50,:],axis=2)\n",
    "err_50 = stats.sem(steps[:50,:],axis=2) #standard error of mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot learning curves with 95% confidence (t_dist standard error Note: this assumes normal distribution of means, probably not true here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "confidence = 0.95\n",
    "#factor for given confidence and number of trials\n",
    "t= stats.t._ppf((1+confidence)/2., numtrials-1)\n",
    "\n",
    "colors=['blue','green','red']\n",
    "for i in range(len(lambdas)):\n",
    "    plt.plot(mean_steps[i,:],label='lambda'+str(lambdas[i]))\n",
    "    plt.fill_between(np.arange(numep),(mean_steps[i,:]-t*err[i,:]),(mean_steps[i,:]+t*err[i,:]),alpha=0.3,color=colors[i])\n",
    "\n",
    "plt.xlabel('episode')\n",
    "plt.ylabel('#steps')\n",
    "plt.ylim((0,1000))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can smooth the curves by taking a running average or applying a filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import gaussian\n",
    "from scipy.ndimage import filters\n",
    "\n",
    "#gaussian filter (running average but closer points have higher weights)\n",
    "def smoothing(x,window,axis=0):\n",
    "    filt = gaussian(window,2.)\n",
    "    return filters.convolve1d(x,filt/np.sum(filt),axis)\n",
    "\n",
    "#standard running average\n",
    "def running_average(x,window,axis=0):\n",
    "    return filters.convolve1d(x,np.ones(window),axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_sm = smoothing(mean_steps,10,1)\n",
    "err_sm = smoothing(err,10,1)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "colors=['blue','green','red']\n",
    "for i in range(len(lambdas)):\n",
    "    plt.plot(mean_sm[i,:],label='lambda'+str(lambdas[i]))\n",
    "    plt.fill_between(np.arange(numep),(mean_sm[i,:]-t*err_sm[i,:]),(mean_sm[i,:]+t*err_sm[i,:]),alpha=0.3,color=colors[i])\n",
    "\n",
    "plt.ylabel('#steps')\n",
    "plt.xlabel('episodes')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and visualize Qvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/SARSA_a_0.5_l_0.0_e_0.05/SARSA_theta.1','rb') as f:\n",
    "    theta = pickle.load(f)\n",
    "values = np.max(theta,axis=1) #greedy state values (max over Q-values) \n",
    "plt.matshow(values.reshape(20,20),vmin=0.,vmax=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/SARSA_a_0.5_l_0.5_e_0.05/SARSA_theta.1','rb') as f:\n",
    "    theta = pickle.load(f)\n",
    "values = np.max(theta,axis=1) #greedy state values (max over Q-values) \n",
    "plt.matshow(values.reshape(20,20),vmin=0.,vmax=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/SARSA_a_0.5_l_1.0_e_0.05/SARSA_theta.1','rb') as f:\n",
    "    theta = pickle.load(f)\n",
    "values = np.max(theta,axis=1) #greedy state values (max over Q-values) \n",
    "plt.matshow(values.reshape(20,20),vmin=0.,vmax=10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare how fast we learn for different lambdas (look at average lengths of first 50 episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "data = [mean_50[0,:],mean_50[1,:],mean_50[2,:]]\n",
    "#lambda values\n",
    "labels=['0','0.5','1']\n",
    "plt.boxplot(data,labels=labels)\n",
    "plt.ylabel('avg steps')\n",
    "plt.xlabel('lambda')\n",
    "plt.title('alpha 0.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load value functions for qlearning/ sarsa for different epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numtrials=10\n",
    "numep = 200\n",
    "alpha =0.5\n",
    "eps = [0.05,0.5,0.9] #try multiple eps\n",
    "lambda_ = 0.5\n",
    "width = 20\n",
    "height = 20\n",
    "\n",
    "#store data in 3d array\n",
    "qlearning = np.zeros((len(eps),width,height))\n",
    "sarsa = np.zeros((len(eps),width,height))\n",
    "\n",
    "for k,e in enumerate(eps):\n",
    "    with open('data/SARSA_a_'+str(alpha)+'_l_'+str(lambda_)+'_e_'+str(e)+'/SARSA_theta.1','rb') as f:\n",
    "        vals = pickle.load(f)\n",
    "        sarsa[k,:,:] = np.max(vals,axis=1).reshape(height,width)\n",
    "    with open('data/Qlearning_a_'+str(alpha)+'_l_'+str(lambda_)+'_e_'+str(e)+'/Qlearning_theta.1','rb') as f:\n",
    "        vals = pickle.load(f)\n",
    "        qlearning[k,:,:] += np.max(vals,axis=1).reshape(height,width)\n",
    "\n",
    "sarsa /= numtrials\n",
    "qlearning /= numtrials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2,3)\n",
    "#first row are sarsa values for different eps\n",
    "for i in range(len(eps)):\n",
    "    axarr[0,i].matshow(sarsa[i,:,:],vmin=0.,vmax=10)\n",
    "\n",
    "#second row are qlearning values\n",
    "for i in range(len(eps)):\n",
    "    axarr[1,i].matshow(qlearning[i,:,:],vmin=0.,vmax=10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'sarsa valuea of start state:'\n",
    "#should decrease with increasing epsilon\n",
    "for i in range(len(eps)):\n",
    "    print sarsa[i,0,0]\n",
    "\n",
    "\n",
    "print 'qlearning values of start state:'\n",
    "#should stay constant with increasing epsilon\n",
    "for i in range(len(eps)):\n",
    "    print qlearning[i,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
